{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9220888,"sourceType":"datasetVersion","datasetId":5568592}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Appliance Energy Augmentation and Forecasting\n\nA project for enhancing appliance energy consumption data using TimeGAN for data augmentation and Facebook's Prophet for time series forecasting.","metadata":{}},{"cell_type":"markdown","source":"# Time Series Forecasting using Facebook's Prophet\n\nIn this notebook, we will use Facebook's Prophet package to forecast energy consumption.\n\n## 1. Introduction\n\nThis notebook focuses on forecasting appliance energy consumption using Facebook's Prophet. The objective is to provide accurate and reliable forecasts based on augmented energy consumption data.\n\n## 2. Background on Time Series Data\n\nTime series data is a sequence of data points collected or recorded at specific time intervals. Understanding the characteristics of time series data, such as trends, seasonality, and noise, is crucial for accurate forecasting.\n\n## 3. Installation of Required Packages\n\n```python\n# Install necessary packages","metadata":{}},{"cell_type":"code","source":"!pip install fpdf\n!pip install pystan==2.19.1.1\n!pip install fbprophet","metadata":{"vscode":{"languageId":"plaintext"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. import required packages\n\n```python\n# Import necessary packages\n","metadata":{}},{"cell_type":"code","source":"import os\nimport shutil\nimport glob\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom fbprophet import Prophet\nfrom fbprophet.diagnostics import cross_validation, performance_metrics\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\n\nimport re\nimport tempfile\nimport warnings\nwarnings.filterwarnings(\"ignore\", message=\".*to_pydatetime.*\")\nfrom fpdf import FPDF\nimport zipfile\nimport pdb\nimport io\n\nprint(\"Import DONE\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Define input and output folders and important variables","metadata":{}},{"cell_type":"code","source":"The_input_folder = r'/kaggle/input/converted-augmented-data'\nThe_output_folder = r'/kaggle/working'\n\nThe_training_start_date = '2024-01-01'\nThe_training_end_date = '2024-12-31'\n\nplot_start_date = '2024-01-01'\nplot_end_date = '2025-12-31'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. Define holidays\n\n#### Define holidays for 2024 in UAE to be used for forecasting","metadata":{}},{"cell_type":"code","source":"# Define holidays\nuae_holidays_2024 = [\n    {\"name\": \"New Year's Day\", \"date\": \"2024-01-01\"},\n    {\"name\": \"Eid Al Fitr\", \"date\": \"2024-04-10\"},\n    {\"name\": \"Eid Al Fitr Holiday\", \"date\": \"2024-04-11\"},\n    {\"name\": \"Eid Al Fitr Holiday\", \"date\": \"2024-04-12\"},\n    {\"name\": \"Arafat Day\", \"date\": \"2024-06-15\"},\n    {\"name\": \"Eid Al Adha\", \"date\": \"2024-06-16\"},\n    {\"name\": \"Eid Al Adha Holiday\", \"date\": \"2024-06-17\"},\n    {\"name\": \"Eid Al Adha Holiday\", \"date\": \"2024-06-18\"},\n    {\"name\": \"Islamic New Year\", \"date\": \"2024-07-07\"},\n    {\"name\": \"Prophet Muhammad's Birthday\", \"date\": \"2024-09-15\"},\n    {\"name\": \"Commemoration Day\", \"date\": \"2024-12-01\"},\n    {\"name\": \"UAE National Day\", \"date\": \"2024-12-02\"},\n    {\"name\": \"UAE National Day Holiday\", \"date\": \"2024-12-03\"}\n]\nholiday_df = pd.DataFrame(uae_holidays_2024)\nholiday_df['ds'] = pd.to_datetime(holiday_df['date'])\nholiday_df = holiday_df[['ds', 'name']].rename(columns={'name': 'holiday'})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. Define helper functions","metadata":{}},{"cell_type":"code","source":"def calculate_mase(y_true, y_pred, window_size=7):\n    \"\"\"\n    Calculate the Mean Absolute Scaled Error (MASE).\n    Parameters:\n    y_true (pandas.Series or numpy.ndarray): The true values.\n    y_pred (pandas.Series or numpy.ndarray): The predicted values.\n    window_size (int): The size of the window for calculating the naive forecast.\n    Returns:\n    float: The MASE value.\n    \"\"\"\n    # Calculate the naive forecast\n    naive_forecast = y_true.shift(1)\n    naive_forecast.iloc[0] = y_true.iloc[0]\n    # Calculate the in-sample MAE of the naive forecast\n    mae_naive = np.mean(np.abs(y_true[window_size:] - naive_forecast[window_size:]))\n    # Calculate the MAE of the model forecast\n    mae_model = np.mean(np.abs(y_true[window_size:] - y_pred[window_size:]))\n    # Calculate the MASE\n    mase = mae_model / mae_naive\n    return mase\n \ndef extract_info(device_name):\n    appliances = [\"Water\", \"Printer\", \"Microwave\", \"Kettle\", \"Fridge\", \"Coffee\", \"PC1\",\"water\", \"printer\", \"microwave\", \"kettle\", \"fridge\", \"coffee\", \"pc1\"]\n    appliance = next((appl for appl in appliances if appl.lower() in device_name.lower()), \"Unknown\")\n    # Extract date (assuming it's the first part before an underscore)\n    date = device_name.split('_')[0] if '_' in device_name else \"Unknown\"\n    # The rest of the string after the appliance name will be considered as status\n    status = device_name.split(appliance)[-1].strip('_') if appliance in device_name else \"Unknown\"\n    return date, appliance, status","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6. Define the main processing function","metadata":{}},{"cell_type":"code","source":"# Function to process each file\ndef process_file(file_path):\n    try:\n        # Read the CSV file\n        df = pd.read_csv(file_path)\n        \n        # Extract device information\n        appliancesList = {\"Water\", \"Printer\", \"Microwave\", \"Kettle\", \"Fridge\", \"Coffee\", \"PC1\",\"water\", \"printer\", \"microwave\", \"kettle\", \"fridge\", \"coffee\", \"pc1\"}\n        device_name = os.path.splitext(os.path.basename(file_path))[0]\n        appliance, date, status, status2 = device_name.split('_')\n        appliance = next((appl for appl in appliancesList if appl in device_name), \"unknown appliance\")\n        \n        # Check if 'time' and 'value' columns exist\n        if 'time' not in df.columns or 'kWh.mean_value' not in df.columns:\n            # Try to identify time and value columns\n            time_col = df.select_dtypes(include=['datetime64', 'object']).columns[0]\n            value_col = df.select_dtypes(include=['float64', 'int64']).columns[0]\n            print(f\"Assuming '{time_col}' as time column and '{value_col}' as value column\")\n            # Rename columns to match Prophet requirements\n            df = df.rename(columns={time_col: 'ds', value_col: 'y'})\n        else:\n            # Rename columns to match Prophet requirements\n            df = df.rename(columns={'time': 'ds', 'kWh.mean_value': 'y'})\n            \n        # Convert 'ds' column to datetime and remove timezone information\n        df['ds'] = pd.to_datetime(df['ds'], utc=True).dt.tz_localize(None)\n        \n        # Define the start and end dates for the time frame\n        start_date = The_training_start_date\n        end_date = The_training_end_date\n \n        # Filter the DataFrame to include only the data within the specified time frame\n        filtered_df = df[(df['ds'] >= start_date) & (df['ds'] <= end_date)]\n \n        # Remove outliers\n        filtered_df = filtered_df[filtered_df['y'] < filtered_df['y'].quantile(0.98)]\n \n        # Add a small constant to avoid log(0)\n        filtered_df['y'] = filtered_df['y'] + 1e-8\n        \n         \n        # Define the Prophet model with holidays and seasonality parameters\n        if appliance == \"Water\":\n            model = Prophet(holidays=holiday_df, weekly_seasonality=True, yearly_seasonality=True, daily_seasonality=True)\n        elif appliance == \"Printer\":\n            model = Prophet(holidays=holiday_df, weekly_seasonality=True, yearly_seasonality=True, daily_seasonality=True)\n        elif appliance == \"Microwave\":\n            model = Prophet(holidays=holiday_df, weekly_seasonality=True, yearly_seasonality=True, daily_seasonality=True)\n        elif appliance == \"Kettle\":\n            model = Prophet(holidays=holiday_df, weekly_seasonality=True, yearly_seasonality=True, daily_seasonality=True)\n        elif appliance == \"Fridge\":\n            model = Prophet(holidays=holiday_df, weekly_seasonality=True, yearly_seasonality=True, daily_seasonality=True)\n        elif appliance == \"Coffee\":\n            model = Prophet(holidays=holiday_df, weekly_seasonality=True, yearly_seasonality=True, daily_seasonality=True)\n        elif appliance == \"PC1\":\n            model = Prophet(holidays=holiday_df, weekly_seasonality=True, yearly_seasonality=True, daily_seasonality=True)\n        else:\n            model = Prophet(holidays=holiday_df, weekly_seasonality=True, yearly_seasonality=True, daily_seasonality=True)\n \n        # Add country holidays\n        model.add_country_holidays(country_name='AE')\n \n        model.fit(filtered_df)\n \n        # Make future dataframe for predictions\n        future = model.make_future_dataframe(periods=360, freq='12h', include_history=True)\n \n        # Make predictions\n        forecast = model.predict(future)\n        # Clip negative forecast values to zero to ensure all predictions are non-negative\n        forecast['yhat'] = forecast['yhat'].clip(lower=0)\n        forecast['yhat_lower'] = forecast['yhat_lower'].clip(lower=0)\n        forecast['yhat_upper'] = forecast['yhat_upper'].clip(lower=0)\n \n        # Get the forecast values only for the time period that corresponds to the original data in df\n        forecast_values = forecast['yhat'][:len(filtered_df)]\n        og_data = df['y'][:len(forecast)]\n        # Replace zeros in df['y'] with a very small number to avoid division by zero, or use conditional to avoid zero division\n        df_non_zero = filtered_df[filtered_df['y'] != 0].copy()\n        forecast_values_non_zero = forecast_values[df['y'] != 0]\n        print(appliance)\n        MSE = np.sqrt(mean_squared_error(y_true=filtered_df['y'], y_pred=forecast_values))\n        MAE = mean_absolute_error(y_true=filtered_df['y'], y_pred=forecast_values)\n        MASE = calculate_mase(filtered_df['y'], forecast_values)\n        \n        print(\"MSE: \", MSE)\n        print(\"MAE: \", MAE)\n        print(\"MASE: \", MASE)\n \n \n        df = df[(df['ds'] >= start_date) & (df['ds'] <= end_date)]\n \n        # Create the plot for forecast\n        fig1, ax1 = plt.subplots(figsize=(21, 10))\n        ax1.plot(df['ds'], df['y'], label='The Original Data', linewidth=2)\n        ax1.plot(forecast['ds'], forecast['yhat'], color='green', label='Forecast', linewidth=2)\n        ax1.set_xlim(pd.Timestamp(plot_start_date), pd.Timestamp(plot_end_date))\n        ax1.fill_between(forecast['ds'], \n                         (forecast['yhat_lower'] + (forecast['yhat_upper'] - forecast['yhat_lower'])*0.1), \n                         (forecast['yhat_upper'] - (forecast['yhat_upper'] - forecast['yhat_lower'])*0.1), \n                         color='green', alpha=0.4)\n        ax1.legend()\n        ax1.set_title('Forecast Plot of ' + date + ' ' + appliance + ' ' +  status)\n        plt.show()\n \n        # Create the components plot\n        fig2 = model.plot_components(forecast, weekly_start=1)\n\n \n        # Save plots to memory\n        img1 = io.BytesIO()\n        fig1.savefig(img1, format='png')\n        img1.seek(0)\n        img2 = io.BytesIO()\n        fig2.savefig(img2, format='png')\n        img2.seek(0)\n        # Clear the plots to free up memory\n        plt.close(fig1)\n        plt.close(fig2)\n        #Save the forecasted data to a CSV file\n        forecasted_data = pd.DataFrame({'ds': future['ds'], 'yhat': forecast['yhat'], 'yhat_lower': forecast['yhat_lower'], 'yhat_upper': forecast['yhat_upper']})\n        forecasted_data.to_csv(os.path.join(The_output_folder, f\"{appliance}_forecasted_data.csv\"), index=False)\n        return file_path, img1, img2\n    except Exception as e:\n        print(f\"Error processing {file_path}: {str(e)}\")\n        return file_path, None, None","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 7. Main function to process files","metadata":{}},{"cell_type":"code","source":"# Main function to process files and generate reports\ndef main():\n    input_folder = The_input_folder\n    output_folder = The_output_folder\n    \n    # Create output folder if it doesn't exist\n    os.makedirs(output_folder, exist_ok=True)\n    \n    # Get list of CSV files\n    csv_files = glob.glob(os.path.join(input_folder, '*.csv'))\n    device_results = {}\n    \n    # Process files sequentially\n    for file in csv_files:\n        file_path, img1, img2 = process_file(file)\n        if img1 and img2:\n            # Store results\n            device_name = os.path.splitext(os.path.basename(file_path))[0]\n            device_results[device_name] = (img1, img2)\n            # Create a subfolder for each device\n            device_folder = os.path.join(output_folder, device_name)\n            os.makedirs(device_folder, exist_ok=True)\n            # Save images\n            with open(os.path.join(device_folder, 'forecast_plot.png'), 'wb') as f:\n                f.write(img1.getvalue())\n            with open(os.path.join(device_folder, 'components_plot.png'), 'wb') as f:\n                f.write(img2.getvalue())\n    print(\"All files processed.\")\n \nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}
